{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "## Part 1: Preprocessing a real world data set from Kaggle showing the London Crimes from 2008 to 2016\u00b6"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Solving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/Python36\n\n  added / updated specs: \n    - geocoder\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    geocoder-1.38.1            |             py_1          53 KB  conda-forge\n    certifi-2019.9.11          |           py36_0         147 KB  conda-forge\n    ratelim-0.1.6              |             py_2           6 KB  conda-forge\n    openssl-1.1.1c             |       h516909a_0         2.1 MB  conda-forge\n    ca-certificates-2019.9.11  |       hecc5488_0         144 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         2.5 MB\n\nThe following NEW packages will be INSTALLED:\n\n    geocoder:        1.38.1-py_1       conda-forge\n    ratelim:         0.1.6-py_2        conda-forge\n\nThe following packages will be UPDATED:\n\n    ca-certificates: 2019.8.28-0                   --> 2019.9.11-hecc5488_0 conda-forge\n    certifi:         2019.9.11-py36_0              --> 2019.9.11-py36_0     conda-forge\n\nThe following packages will be DOWNGRADED:\n\n    openssl:         1.1.1d-h7b6447c_2             --> 1.1.1c-h516909a_0    conda-forge\n\n\nDownloading and Extracting Packages\ngeocoder-1.38.1      | 53 KB     | ##################################### | 100% \ncertifi-2019.9.11    | 147 KB    | ##################################### | 100% \nratelim-0.1.6        | 6 KB      | ##################################### | 100% \nopenssl-1.1.1c       | 2.1 MB    | ##################################### | 100% \nca-certificates-2019 | 144 KB    | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/Python36\n\n  added / updated specs: \n    - geopy\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    geographiclib-1.50         |             py_0          34 KB  conda-forge\n    geopy-1.20.0               |             py_0          57 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:          91 KB\n\nThe following NEW packages will be INSTALLED:\n\n    geographiclib: 1.50-py_0   conda-forge\n    geopy:         1.20.0-py_0 conda-forge\n\n\nDownloading and Extracting Packages\ngeographiclib-1.50   | 34 KB     | ##################################### | 100% \ngeopy-1.20.0         | 57 KB     | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/Python36\n\n  added / updated specs: \n    - folium=0.5.0\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    branca-0.3.1               |             py_0          25 KB  conda-forge\n    vincent-0.4.4              |             py_1          28 KB  conda-forge\n    altair-3.2.0               |           py36_0         770 KB  conda-forge\n    folium-0.5.0               |             py_0          45 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         868 KB\n\nThe following NEW packages will be INSTALLED:\n\n    altair:  3.2.0-py36_0 conda-forge\n    branca:  0.3.1-py_0   conda-forge\n    folium:  0.5.0-py_0   conda-forge\n    vincent: 0.4.4-py_1   conda-forge\n\n\nDownloading and Extracting Packages\nbranca-0.3.1         | 25 KB     | ##################################### | 100% \nvincent-0.4.4        | 28 KB     | ##################################### | 100% \naltair-3.2.0         | 770 KB    | ##################################### | 100% \nfolium-0.5.0         | 45 KB     | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nFolium installed\nLibraries imported.\n"
                }
            ],
            "source": "import requests # library to handle requests\nimport pandas as pd # library for data analsysis\nimport numpy as np # library to handle data in a vectorized manner\nimport random # library for random number generation\nfrom bs4 import BeautifulSoup # library for web scrapping  \n\n!conda install -c conda-forge geocoder --yes\nimport geocoder\n\n!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\n\n# libraries for displaying images\nfrom IPython.display import Image \nfrom IPython.core.display import HTML \n    \n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\n\n!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # plotting library\n\nprint('Folium installed')\nprint('Libraries imported.')"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Your credentails:\nCLIENT_ID: R01LINGO2WC45KLRLKT3ZHU2QENAO2IPRK2N2ELOHRNK4P3K\nCLIENT_SECRET:4JT1TWRMXMPLX5IOKNBAFU3L3ARXK4D5JJDPFK1CLRZM2ZVW\n"
                }
            ],
            "source": "CLIENT_ID = 'R01LINGO2WC45KLRLKT3ZHU2QENAO2IPRK2N2ELOHRNK4P3K' # your Foursquare ID\nCLIENT_SECRET = '4JT1TWRMXMPLX5IOKNBAFU3L3ARXK4D5JJDPFK1CLRZM2ZVW' # your Foursquare Secret\n\nVERSION = '20180604'\nLIMIT = 30\n\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] File b'london_crime_by_lsoa.csv' does not exist: b'london_crime_by_lsoa.csv'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-4-229f68ae418f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"london_crime_by_lsoa.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'london_crime_by_lsoa.csv' does not exist: b'london_crime_by_lsoa.csv'"
                    ]
                }
            ],
            "source": "df = pd.read_csv(r\"london_crime_by_lsoa.csv\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.drop(df.index[df['year'] != 2016], inplace = True)\n\n# Removing all the entires where crime values are null  \ndf = df[df.value != 0]\n\n# Reset the index and dropping the previous index\ndf = df.reset_index(drop=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.columns = ['LSOA_Code', 'Borough','Major_Category','Minor_Category','No_of_Crimes','Year','Month']\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.info()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df['Borough'].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df['Major_Category'].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_crime = pd.pivot_table(df,values=['No_of_Crimes'],\n                               index=['Borough'],\n                               columns=['Major_Category'],\n                               aggfunc=np.sum,fill_value=0)\nLondon_crime.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_crime.reset_index(inplace = True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_crime['Total'] = London_crime.sum(axis=1)\nLondon_crime.head(33)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_crime.columns = London_crime.columns.map(''.join)\nLondon_crime.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_crime.columns = ['Borough','Burglary', 'Criminal Damage','Drugs','Other Notifiable Offences',\n                        'Robbery','Theft and Handling','Violence Against the Person','Total']\nLondon_crime.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_crime.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "##  Part 2: Scraping additional information of the different Boroughs in London from a Wikipedia page \nUsing Beautiful soup to scrap the latitude and longitiude of the boroughs in London\n\nURL: https://en.wikipedia.org/wiki/List_of_London_boroughs"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "wikipedia_link='https://en.wikipedia.org/wiki/List_of_London_boroughs'\nraw_wikipedia_page= requests.get(wikipedia_link).text\n\n# using beautiful soup to parse the HTML/XML codes.\nsoup = BeautifulSoup(raw_wikipedia_page,'xml')\nprint(soup.prettify())"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_table = pd.read_html(str(table[0]), index_col=None, header=0)[0]\nLondon_table.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_table1 = pd.read_html(str(table[1]), index_col=None, header=0)[0]\n\n# Rename the columns to match the previous table to append the tables.\n\nLondon_table1.columns = ['Borough','Inner','Status','Local authority','Political control',\n                         'Headquarters','Area (sq mi)','Population (2013 est)[1]','Co-ordinates','Nr. in map']\n\n# View the table\nLondon_table1"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\nLondon_table = London_table.append(London_table1, ignore_index = True) \nLondon_table.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_table.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_table.info()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_table = London_table.replace('note 1','', regex=True) \nLondon_table = London_table.replace('note 2','', regex=True) \nLondon_table = London_table.replace('note 3','', regex=True) \nLondon_table = London_table.replace('note 4','', regex=True) \nLondon_table = London_table.replace('note 5','', regex=True) \n\n# View the top of the data set\nLondon_table.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "type(London_table)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_table.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "set(df.Borough) - set(London_table.Borough)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(\"The index of first borough is\",London_table.index[London_table['Borough'] == 'Barking and Dagenham []'].tolist())\nprint(\"The index of second borough is\",London_table.index[London_table['Borough'] == 'Greenwich []'].tolist())\nprint(\"The index of third borough is\",London_table.index[London_table['Borough'] == 'Hammersmith and Fulham []'].tolist())"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_table.iloc[0,0] = 'Barking and Dagenham'\nLondon_table.iloc[9,0] = 'Greenwich'\nLondon_table.iloc[11,0] = 'Hammersmith and Fulham'"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "set(df.Borough) - set(London_table.Borough)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Ld_crime = pd.merge(London_crime, London_table, on='Borough')\nLd_crime.head(10)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Ld_crime.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "set(df.Borough) - set(Ld_crime.Borough)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "list(Ld_crime)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "columnsTitles = ['Borough','Local authority','Political control','Headquarters',\n                 'Area (sq mi)','Population (2013 est)[1]',\n                 'Inner','Status',\n                 'Burglary','Criminal Damage','Drugs','Other Notifiable Offences',\n                 'Robbery','Theft and Handling','Violence Against the Person','Total','Co-ordinates']\n\nLd_crime = Ld_crime.reindex(columns=columnsTitles)\n\nLd_crime = Ld_crime[['Borough','Local authority','Political control','Headquarters',\n                 'Area (sq mi)','Population (2013 est)[1]','Co-ordinates',\n                 'Burglary','Criminal Damage','Drugs','Other Notifiable Offences',\n                 'Robbery','Theft and Handling','Violence Against the Person','Total']]\n\nLd_crime.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Methodology \nThe methodology in this project consists of two parts:\n\nExploratory Data Analysis: Visualise the crime rates in the London boroughs to idenity the safest borough and extract the neighborhoods in that borough to find the 10 most common venues in each neighborhood.\n\nModelling: To help people find similar neighborhoods in the safest borough we will be clustering similar neighborhoods using K - means clustering which is a form of unsupervised machine learning algorithm that clusters data based on predefined cluster size. We will use a cluster size of 5 for this project that will cluster the 15 neighborhoods into 5 clusters. \nThe reason to conduct a K- means clustering is to cluster neighborhoods with similar venues together so that people can shortlist the area of their interests based on the venues/amenities around each neighborhood."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "London_crime.describe()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "%matplotlib inline \n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nmpl.style.use('ggplot') # optional: for ggplot-like style\n\n# check for latest version of Matplotlib\nprint ('Matplotlib version: ', mpl.__version__) # >= 2.0.0\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Ld_crime.sort_values(['Total'], ascending = False, axis = 0, inplace = True )\n\ndf_top5 = Ld_crime.head() \ndf_top5"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_tt = df_top5[['Borough','Total']]\n\ndf_tt.set_index('Borough',inplace = True)\n\nax = df_tt.plot(kind='bar', figsize=(10, 6), rot=0)\n\nax.set_ylabel('Number of Crimes') # add to x-label to the plot\nax.set_xlabel('Borough') # add y-label to the plot\nax.set_title('London Boroughs with the Highest no. of crime') # add title to the plot\n\n# Creating a function to display the percentage.\n\nfor p in ax.patches:\n    ax.annotate(np.round(p.get_height(),decimals=2), \n                (p.get_x()+p.get_width()/2., p.get_height()), \n                ha='center', \n                va='center', \n                xytext=(0, 10), \n                textcoords='offset points',\n                fontsize = 14\n               )\n\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Ld_crime.sort_values(['Total'], ascending = True, axis = 0, inplace = True )\n\ndf_bot5 = Ld_crime.head() \ndf_bot5"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_bt = df_bot5[['Borough','Total']]\n\ndf_bt.set_index('Borough',inplace = True)\n\nax = df_bt.plot(kind='bar', figsize=(10, 6), rot=0)\n\nax.set_ylabel('Number of Crimes') # add to x-label to the plot\nax.set_xlabel('Borough') # add y-label to the plot\nax.set_title('London Boroughs with the least no. of crime') # add title to the plot\n\n# Creating a function to display the percentage.\n\nfor p in ax.patches:\n    ax.annotate(np.round(p.get_height(),decimals=2), \n                (p.get_x()+p.get_width()/2., p.get_height()), \n                ha='center', \n                va='center', \n                xytext=(0, 10), \n                textcoords='offset points',\n                fontsize = 14\n               )\n\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_col = df_bot5[df_bot5['Borough'] == 'City of London']\ndf_col = df_col[['Borough','Total','Area (sq mi)','Population (2013 est)[1]']]\ndf_col"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Visualizing different types of crimes in the borough 'Kingston upon Thames'"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_bc1 =  df_bot5[df_bot5['Borough'] == 'Kingston upon Thames']\n\ndf_bc = df_bc1[['Borough','Burglary','Criminal Damage','Drugs','Other Notifiable Offences',\n                 'Robbery','Theft and Handling','Violence Against the Person']]\n\n\ndf_bc.set_index('Borough',inplace = True)\n\nax = df_bc.plot(kind='bar', figsize=(10, 6), rot=0)\n\nax.set_ylabel('Number of Crimes') # add to x-label to the plot\nax.set_xlabel('Borough') # add y-label to the plot\nax.set_title('London Boroughs with the least no. of crime') # add title to the plot\n\n# Creating a function to display the percentage.\n\nfor p in ax.patches:\n    ax.annotate(np.round(p.get_height(),decimals=2), \n                (p.get_x()+p.get_width()/2., p.get_height()), \n                ha='center', \n                va='center', \n                xytext=(0, 10), \n                textcoords='offset points',\n                fontsize = 14\n               )\n\nplt.show()\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "##  Part 3: Creating a new dataset of the Neighborhoods of the safest borough in London and generating their co-ordinates. \u00b6"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Neighborhood = ['Berrylands','Canbury','Chessington','Coombe','Hook','Kingston upon Thames',\n'Kingston Vale','Malden Rushett','Motspur Park','New Malden','Norbiton',\n'Old Malden','Seething Wells','Surbiton','Tolworth']\n\nBorough = ['Kingston upon Thames','Kingston upon Thames','Kingston upon Thames','Kingston upon Thames',\n          'Kingston upon Thames','Kingston upon Thames','Kingston upon Thames','Kingston upon Thames',\n          'Kingston upon Thames','Kingston upon Thames','Kingston upon Thames','Kingston upon Thames',\n          'Kingston upon Thames','Kingston upon Thames','Kingston upon Thames']\n\nLatitude = ['','','','','','','','','','','','','','','']\nLongitude = ['','','','','','','','','','','','','','','']\n\ndf_neigh = {'Neighborhood': Neighborhood,'Borough':Borough,'Latitude': Latitude,'Longitude':Longitude}\nkut_neig = pd.DataFrame(data=df_neigh, columns=['Neighborhood', 'Borough', 'Latitude', 'Longitude'], index=None)\n\nkut_neig"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Latitude = []\nLongitude = []\n\nfor i in range(len(Neighborhood)):\n    address = '{},London,United Kingdom'.format(Neighborhood[i])\n    geolocator = Nominatim(user_agent=\"London_agent\")\n    location = geolocator.geocode(address)\n    Latitude.append(location.latitude)\n    Longitude.append(location.longitude)\nprint(Latitude, Longitude)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_neigh = {'Neighborhood': Neighborhood,'Borough':Borough,'Latitude': Latitude,'Longitude':Longitude}\nkut_neig = pd.DataFrame(data=df_neigh, columns=['Neighborhood', 'Borough', 'Latitude', 'Longitude'], index=None)\n\nkut_neig"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "address = 'Berrylands, London, United Kingdom'\n\ngeolocator = Nominatim(user_agent=\"ld_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Berrylands, London are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "map_lon = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(kut_neig['Latitude'], kut_neig['Longitude'], kut_neig['Borough'], kut_neig['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_lon)  \n    \nmap_lon"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kut_venues = getNearbyVenues(names=kut_neig['Neighborhood'],\n                                   latitudes=kut_neig['Latitude'],\n                                   longitudes=kut_neig['Longitude']\n                                  )"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(kut_venues.shape)\nkut_venues.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kut_venues.groupby('Neighborhood').count()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('There are {} uniques categories.'.format(len(kut_venues['Venue Category'].unique())))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kut_onehot = pd.get_dummies(kut_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\nkut_onehot['Neighborhood'] = kut_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [kut_onehot.columns[-1]] + list(kut_onehot.columns[:-1])\nkut_onehot = kut_onehot[fixed_columns]\n\nkut_onehot.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kut_grouped = kut_onehot.groupby('Neighborhood').mean().reset_index()\nkut_grouped"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kut_grouped.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 5\n\nfor hood in kut_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = kut_grouped[kut_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = kut_grouped['Neighborhood']\n\nfor ind in np.arange(kut_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(kut_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n# set number of clusters\nkclusters = 5\n\nkut_grouped_clustering = kut_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(kut_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\nkut_merged = kut_neig\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\nkut_merged = kut_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\nkut_merged.head() # check the last columns!\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kut_merged.dropna(inplace = True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kut_merged['Cluster Labels'] = kut_merged['Cluster Labels'].astype(int)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11.5)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(kut_merged['Latitude'], kut_merged['Longitude'], kut_merged['Neighborhood'], kut_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=8,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.5).add_to(map_clusters)\n       \nmap_clusters"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "###  Analysis \nAnalyse each of the clusters to identify the characteristics of each cluster and the neighborhoods in them."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kut_merged[kut_merged['Cluster Labels'] == 0]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kut_merged[kut_merged['Cluster Labels'] == 1]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kut_merged[kut_merged['Cluster Labels'] == 2]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kut_merged[kut_merged['Cluster Labels'] == 3]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kut_merged[kut_merged['Cluster Labels'] == 4]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Results and Discussion \nThe aim of this project is to help people who want to relocate to the safest borough in London, expats can chose the neighborhoods to which they want to relocate based on the most common venues in it. For example if a person is looking for a neighborhood with good connectivity and public transportation we can see that Clusters 3 and 4 have Train stations and Bus stops as the most common venues. If a person is looking for a neighborhood with stores and restaurants in a close proximity then the neighborhoods in the first cluster is suitable. For a family I feel that the neighborhoods in Cluster 4 are more suitable dues to the common venues in that cluster, these neighborhoods have common venues such as Parks, Gym/Fitness centers, Bus Stops, Restaurants, Electronics Stores and Soccer fields which is ideal for a family.\n\n### Conclusion \nThis project helps a person get a better understanding of the neighborhoods with respect to the most common venues in that neighborhood. It is always helpful to make use of technology to stay one step ahead i.e. finding out more about places before moving into a neighborhood. We have just taken safety as a primary concern to shortlist the borough of London. The future of this project includes taking other factors such as cost of living in the areas into consideration to shortlist the borough based on safety and a predefined budget."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}